{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T06:49:26.197821Z",
     "start_time": "2020-12-31T06:49:23.416857Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T06:44:58.721879Z",
     "start_time": "2020-12-31T06:44:21.516191Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating a pdf file object \n",
    "# pdfFileObj = open('./data/am_one.pdf', 'rb'\n",
    "# text = extract_text('./data/am_one.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T06:52:35.508552Z",
     "start_time": "2020-12-31T06:52:34.891703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fontname': 'AdvPS6F00', 'adv': Decimal('0.614'), 'upright': True, 'x0': Decimal('137.820'), 'y0': Decimal('667.835'), 'x1': Decimal('143.937'), 'y1': Decimal('677.797'), 'width': Decimal('6.117'), 'height': Decimal('9.963'), 'size': Decimal('9.963'), 'object_type': 'char', 'page_number': 27, 'stroking_color': None, 'non_stroking_color': (0, 0, 0), 'text': 'T', 'top': Decimal('99.203'), 'bottom': Decimal('109.165'), 'doctop': Decimal('20499.370')}\n"
     ]
    }
   ],
   "source": [
    "pdf = pdfplumber.open(\"./data/am_one.pdf\")\n",
    "first_page = pdf.pages[26]\n",
    "print(first_page.chars[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T09:10:06.323279Z",
     "start_time": "2020-12-31T09:10:06.309142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_page = 91\n",
    "end_page = 420\n",
    "first_page = pdf.pages[133]\n",
    "text = first_page.extract_text(x_tolerance=1, y_tolerance=3)\n",
    "# print(text)\n",
    "# text.split('REFERENCES')\n",
    "# text.replace('\\n',' ').lower()\n",
    "len([foo[2] for foo in text.split('\\n') if foo[2] == '.']) > 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T09:17:48.099738Z",
     "start_time": "2020-12-31T09:17:46.872042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770639"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generating text\n",
    "\n",
    "def is_references_page(page_text):\n",
    "    lines = page_text.split('\\n')\n",
    "    counter = 0\n",
    "    for line in lines:\n",
    "        if len(line) > 30:\n",
    "            if line[2] == '.' or line[3] == '.':\n",
    "                counter = counter + 1\n",
    "    if counter > 3:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "all_pages_text = ''\n",
    "counter_w = 0\n",
    "for page_number in range(91, 420):\n",
    "    first_page = pdf.pages[page_number]\n",
    "    page_text = first_page.extract_text(x_tolerance=1, y_tolerance=3)\n",
    "    if page_text:\n",
    "        page_text = page_text.split('REFERENCES')[0]\n",
    "        references_page = is_references_page(page_text)\n",
    "        if not references_page:\n",
    "            # counter_w = counter_w + 1\n",
    "            # print(\"============\")\n",
    "            # print(page_text)\n",
    "            page_text = page_text.replace('\\n',' ').lower()\n",
    "            all_pages_text = all_pages_text + page_text\n",
    "    \n",
    "# print(all_pages_text)\n",
    "len(all_pages_text)\n",
    "# counter_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T07:37:04.167213Z",
     "start_time": "2020-12-31T07:36:49.949393Z"
    }
   },
   "outputs": [],
   "source": [
    "# entites generator\n",
    "# importing modules\n",
    "import spacy\n",
    "import scispacy\n",
    "# import pandas as pd\n",
    "\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_sci_lg\")\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "properties_ruler = EntityRuler(nlp).from_disk(\"./data/am.jsonl\")\n",
    "nlp.add_pipe(properties_ruler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T08:00:39.695444Z",
     "start_time": "2020-12-31T08:00:15.821850Z"
    }
   },
   "outputs": [],
   "source": [
    "# entitties\n",
    "doc = nlp(all_pages_text.lower())\n",
    "entities = []\n",
    "for ent in doc.ents:\n",
    "    # print(\"------------\")\n",
    "    # if ent.label_ in [\"AMPROP\", \"AMING\"]:\n",
    "    # print(ent.label_)\n",
    "    # print(ent.text)\n",
    "    entities.append([ent.text, ent.label_])\n",
    "\n",
    "# entities = list(set(entities))\n",
    "#len(entities)\n",
    "# entities\n",
    "# all_pages_text[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T08:00:43.160066Z",
     "start_time": "2020-12-31T08:00:43.000642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             text   label\n",
      "42347               (121).topical  ENTITY\n",
      "35235              (15–30%),herbs  ENTITY\n",
      "20575                (21).medical  ENTITY\n",
      "21005                    (24).228  ENTITY\n",
      "1340                  (26).toners  ENTITY\n",
      "...                           ...     ...\n",
      "2584                  ﬂuorescence  ENTITY\n",
      "39574  ﬂuorescent dna binding dye  ENTITY\n",
      "26516                  ﬂuorescing  ENTITY\n",
      "14029            ﬂushing response  ENTITY\n",
      "28588                    ﬂutamide  ENTITY\n",
      "\n",
      "[14672 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "entities_df = pd.DataFrame(entities)\n",
    "\n",
    "entities_df.columns = [\"text\", \"label\"]\n",
    "entities_df = entities_df.drop_duplicates()\n",
    "entities_df = entities_df.sort_values(by='text')\n",
    "print(entities_df)\n",
    "entities_df.to_csv('data/am_one_entities.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T09:18:20.814905Z",
     "start_time": "2020-12-31T09:18:00.929017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68741"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens\n",
    "doc = nlp(all_pages_text.lower())\n",
    "tokens = []\n",
    "for token in doc:\n",
    "    if token.pos_ not in [\n",
    "        'AUX', 'PUNCT', 'ADV', 'SPACE', 'DET', 'PART', 'ADP', 'CCONJ', 'NUM']:\n",
    "        tokens.append([token.text, token.pos_, token.tag_])\n",
    "\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T09:18:26.460583Z",
     "start_time": "2020-12-31T09:18:26.272621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6840, 3)\n"
     ]
    }
   ],
   "source": [
    "tokens_df = pd.DataFrame(tokens)\n",
    "\n",
    "tokens_df.columns = [\"text\", \"pos\", \"tag\"]\n",
    "tokens_df = tokens_df.loc[tokens_df['pos'] == 'NOUN']\n",
    "# del tokens_df[\"pos\"]\n",
    "# del tokens_df[\"tag\"]\n",
    "tokens_df = tokens_df.drop_duplicates()\n",
    "tokens_df = tokens_df.sort_values(by='text')\n",
    "print(tokens_df.shape)\n",
    "tokens_df.to_csv('data/am_one_tokens.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T13:54:04.548873Z",
     "start_time": "2020-12-31T13:54:04.330426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_df = pd.DataFrame(tokens)\n",
    "\n",
    "tokens_df.columns = [\"text\", \"pos\", \"tag\"]\n",
    "\n",
    "tokens_df[\"len\"] = tokens_df[\"text\"].apply(lambda x: len(x))\n",
    "tokens_df[\"is_alpha\"] = tokens_df[\"text\"].apply(lambda x: x.isalpha())\n",
    "tokens_df = tokens_df.loc[tokens_df['pos'] == 'NOUN']\n",
    "tokens_df = tokens_df.loc[tokens_df['len'] > 2]\n",
    "tokens_df = tokens_df.loc[tokens_df['len'] < 20]\n",
    "tokens_df = tokens_df.loc[tokens_df['is_alpha']]\n",
    "# print(tokens_df.head())\n",
    "\n",
    "\n",
    "del tokens_df[\"pos\"]\n",
    "del tokens_df[\"tag\"]\n",
    "foo = tokens_df[\"text\"].value_counts()\n",
    "foo = foo.reset_index()\n",
    "foo.columns = ['text', 'count']\n",
    "foo.head()\n",
    "foo.to_csv('data/am_one_token_frequency.csv', index=False)\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# tokens_df.is_alpha.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T14:05:00.790167Z",
     "start_time": "2020-12-31T14:05:00.660794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8975"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# doc = nlp(\"Autonomous cars shift insurance liability toward manufacturers\")\n",
    "chuncks = []\n",
    "for chunk in doc.noun_chunks:\n",
    "    # print(chunk.text)\n",
    "    chuncks.append(chunk.text)\n",
    "    \n",
    "# len(chuncks)\n",
    "len(list(set(chuncks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T14:16:19.042443Z",
     "start_time": "2020-12-31T14:16:18.985330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7858, 2)\n"
     ]
    }
   ],
   "source": [
    "chuncks_df = pd.DataFrame(chuncks)\n",
    "chuncks_df.columns = [\"text\"]\n",
    "\n",
    "chuncks_df[\"len\"] = chuncks_df[\"text\"].apply(lambda x: len(x))\n",
    "# chuncks_df[\"is_alpha\"] = chuncks_df[\"text\"].apply(lambda x: x.isalpha())\n",
    "chuncks_df = chuncks_df.loc[chuncks_df['len'] > 2]\n",
    "chuncks_df = chuncks_df.loc[chuncks_df['len'] < 30]\n",
    "# chuncks_df = chuncks_df.loc[chuncks_df['is_alpha']]\n",
    "chuncks_df = chuncks_df.drop_duplicates()\n",
    "\n",
    "print(chuncks_df.shape)\n",
    "chuncks_df.to_csv(\"data/am_one_chuncks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T06:41:50.122757Z",
     "start_time": "2020-12-31T06:41:50.013623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451\n"
     ]
    }
   ],
   "source": [
    "# creating a pdf reader object \n",
    "pdfReader = PyPDF4.PdfFileReader(pdfFileObj) \n",
    "  \n",
    "# printing number of pages \n",
    "print(pdfReader.numPages) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T06:41:51.572531Z",
     "start_time": "2020-12-31T06:41:51.558720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thenextsectionofthebookdiscussesformulationdevelopmentandapplicationin\n",
      "thebasicskincareareas:cleansers,toners,moisturizers,andantiperspirants.These\n",
      "\n",
      "chaptersareallwrittenbyresearchanddevelopmentscientistsinindustrywithan\n",
      "\n",
      "understandingofhowtheseproductsfunction.Thechapterspresentthebasicanatomy\n",
      "\n",
      "andphysiologyoftheskinimpactedbytheproduct,ingredients,keyconsiderations,and\n",
      "\n",
      "methodsforproductevaluationandtesting.Thedermatologicperspectiveontheuseand\n",
      "\n",
      "selectionoftheseskincareproductsisalsopresented.\n",
      "Lastly,thebookpresentsanup-to-datelookatmanyoftheactiveproductsthatform\n",
      "thecosmeceuticalarenatoinclude:sunscreens,skinlighteningagents,exfoliants,and\n",
      "anti-agingskincareproducts.Thedermatologicperspectiveoneachoftheseareasfollows\n",
      "\n",
      "withadiscussionofsunscreensinrelationtoskincancerprevention,theimpactof\n",
      "\n",
      "cosmeceuticalsontheskin,medicaltherapiesforskinlightening,andacnetreatment\n",
      "\n",
      "methodologies.Thisapproachallowsthedermatologisttobetterunderstandhowthese\n",
      "\n",
      "productsareconstructed,butalsohelpstheindustryresearchertoviewproductsfroma\n",
      "\n",
      "medicalperspectivethatbridgestheover-the-counterandprescriptionworlds.Thetext\n",
      "\n",
      "thenlooksattheworldofbotanicals,anti-inßammatories,andantioxidants.SpeciÞcraw\n",
      "materialsarediscussedbybothindustryresearchersanddermatologistswithan\n",
      "encyclopedicreviewofbotanicalsthatarerelevanttoskincare.\n",
      "Thus,thetextpresentsskincare,formulation,andrawmaterialselectionissues\n",
      "pursuingauniquemultidisciplinaryapproachtothetopic.AspartoftheMarcelDekker\n",
      "\n",
      "CosmeticScienceandTechnologyseries,thistextcanserveasanintroductiontosomeof\n",
      "\n",
      "themoreproductspeciÞctextsintheseriesthatdealsolelywithmoisturizers,cleansers,\n",
      "\n",
      "antiperspirants,etc.Thistextcanprovidethe33yearsofknowledgenecessaryto\n",
      "\n",
      "understandskincareformulation.\n",
      "Draelos\n",
      "2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating a page object \n",
    "pageObj = pdfReader.getPage(26) \n",
    "  \n",
    "# extracting text from page \n",
    "print(pageObj.extractText()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New heading"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
